# Mcrobial profiling Using `mothur` {#mothur-pipeline}

## Download a Mothur trained classifer
- For demo purposes we will use [Silva seed](https://mothur.org/wiki/Silva_reference_files) due to its smaller size.
- Other classifiers can be found [here](https://mothur.org/wiki/taxonomy_outline/).

```bash
wget https://mothur.s3.us-east-2.amazonaws.com/wiki/silva.seed_v138_1.tgz
tar xvzf silva.seed_v138_1.tgz
rm *.tgz
```

## Mothur basic wrapper
- Below is a minimal wrapper for sequence processing, classification and taxonomic assignment using `mothur` pipeline.
- For more information refer to `mothur` [MiSeq SOP](https://mothur.org/wiki/miseq_sop/).
- We can save this wrapper as `mothur_code.batch` and place it in a folder named code.
- Then we will run the file on command line as shown below. See the commented lines.
- We assume that the input data is gunzipped i.e. **.fastq.gz**. If not run `gzip *.fastq` to compress the files.

```{block, type="tmbalert", echo=TRUE}
1. Note that the [`shebang line`](https://en.wikipedia.org/wiki/Shebang_(Unix)) remind us that we are running the analysis on `mothur` command line NOT `bash`. This takes the advantage of using the **current** option to refer to the last saved file.
2. If not generating the mapping file automatically you should make sure that it confer to accepted format as in `mothur_mapping_files.tsv` described in the previous section. In this demo we use `bush.files`. This means that all output files will be prefixed with the term <u>bush</u> to reflect the name of the project. Try to avoid loner names.
```


```bash
#!/mothur

# Usage: mothur code/mothur_code.batch # if mothur is in the path
# Usage: ./mothur code/mothur_code.batch # on mac/linux if the executable `mothur` is in the working directory.
# Usage: ./mothur.exe code/mothur_code.batch # on Windows machins if the executable `mothur.exe` is in the working directory.

set.current(processors=1)
# set.logfile(name=make_files.logfile)
# make.file(inputdir=., type=fastq.gz, prefix=test)

set.logfile(name=seq_assembly.logfile)
make.contigs(file=bush.files, outputdir=./test, maxambig=0, maxlength=275);
unique.seqs(count=current);
summary.seqs(fasta=current, count=current)

set.logfile(name=seq_align_preclustering.logfile)
align.seqs(fasta=current, reference=silva.seed_v138_1.align);
screen.seqs(fasta=current, count=current, start=13862, end=23444, maxhomop=8);
filter.seqs(fasta=current, vertical=T, trump=.);
pre.cluster(fasta=current, count=current, diffs=2);
unique.seqs(fasta=current, count=current);

set.logfile(name=chimera_removal.logfile)
chimera.vsearch(fasta=current, count=current, dereplicate=t);

set.logfile(name=silva_seed_classification.logfile)
classify.seqs(fasta=current, count=current, reference=silva.seed_v138_1.align, taxonomy=silva.seed_v138_1.tax, cutoff=100);
remove.lineage(fasta=current, count=current, taxonomy=current, taxon=Chloroplast-Mitochondria-unknown-Archaea-Eukaryota);

set.logfile(name=final_files.logfile)
rename.file(fasta=current, count=current, taxonomy=current, prefix=final)

set.logfile(name=otu_clustering.logfile)
dist.seqs(fasta=current, cutoff=0.03);
cluster(column=current, count=current, cutoff=0.03);
make.shared(list=current, count=current, label=0.03);
classify.otu(list=current, count=current, taxonomy=current, label=0.03);
make.lefse(shared=current, constaxonomy=current);
make.biom(shared=current, constaxonomy=current);

set.logfile(name=phylotype_clustering.logfile)
phylotype(taxonomy=current);
make.shared(list=current, count=current, label=1);
classify.otu(list=current, count=current, taxonomy=current, label=1);
make.lefse(shared=current, constaxonomy=current);
make.biom(shared=current, constaxonomy=current);

set.logfile(name=asv_clustering.logfile)
make.shared(count=current)
classify.otu(list=current, count=current, taxonomy=current, label=ASV)
make.lefse(shared=current, constaxonomy=current)
make.biom(shared=current, constaxonomy=current)

set.logfile(name=phylogenetic_clustering.logfile)
dist.seqs(fasta=current, output=lt)
clearcut(phylip=current)
```

<br>

# Mcrobial Profiling Using `qiime2` {#qiime2-pipeline}

## Prerequisites

### Download a QIIME2 trained classifer
- You can use Naive Bayes (nb) classifiers trained on GreenGenes or SILVA database with 99% OTUs. You can train your own classifier using the [q2-feature-classifier](https://github.com/qiime2/q2-feature-classifier).

Here we will download the smallest classifier, the naive classifier trained on [Greengenes 13_8 99% OTUs from 515F/806R region of sequences](https://docs.qiime2.org/2022.2/data-resources/)

```bash
wget \
  -O "gg-13-8-99-515-806-nb-classifier.qza" \
  "https://data.qiime2.org/2022.2/common/gg-13-8-99-515-806-nb-classifier.qza"
```

### Install qiime2
- We assumes that you have already installed QIIME 2. If not please do so using the instructions described [here!](https://docs.qiime2.org/2022.2/install/). Below is a simple demo for installing qiime2 on Mac OS.

```bash
wget https://data.qiime2.org/distro/core/qiime2-2022.2-py38-osx-conda.yml
conda env create -n qiime2-2022.2 --file qiime2-2022.2-py38-osx-conda.yml
rm qiime2-2022.2-py39-osx-conda.yml
```

### Running QIIME2 commands
- We prefer to use the command line interface [g2cli](https://docs.qiime2.org/2022.2/interfaces/q2cli/).
- Activate the qiime2 environment: We are using qiime2-2022.2.


### Activate qiime environment
```bash
conda activate qiime2-2022.2
```

### Confirm installation
```bash
qiime info
```

### Validate associated metadata
```bash
qiime tools inspect-metadata \
  $PWD/q2-metadata.tsv
```

### Tabulate metadata in QIIME2 format
```bash
qiime metadata tabulate \
  --m-input-file $PWD/q2-metadata.tsv \
  --o-visualization $PWD/qiime2_bushmeat/sample-metadata.qzv
```

### Visualizing tabulated metadata
```bash
qiime tools view $PWD/qiime2_bushmeat/sample-metadata.qzv
```

## Import paired-end fastq files
```bash
qiime tools import \
  --type 'SampleData[PairedEndSequencesWithQuality]' \
  --input-path $PWD/pe-33-manifest.tsv \
  --output-path $PWD/qiime2_bushmeat/demux.qza \
  --input-format PairedEndFastqManifestPhred33V2
```

### Summarize and visualize preliminary analysis
```bash
qiime demux summarize \
  --i-data $PWD/qiime2_bushmeat/demux.qza \
  --o-visualization $PWD/qiime2_bushmeat/demux.qzv
```
```bash
qiime tools view $PWD/qiime2_bushmeat/demux.qzv
```

> Review and pick truncation parameters if needed.

## Microbial profiling pipeline
- Here we can set the parameters as desired.
- Note that this may take a while, please be patient.
- In addition to setting the STAR and END time, we also optionally use `time` to gauge the amount of time used for some analysis.

```bash
START=`date +%s`

time qiime dada2 denoise-paired \
  --i-demultiplexed-seqs $PWD/qiime2_bushmeat/demux.qza \
  --p-trim-left-f 0 \
  --p-trunc-len-f 0 \
  --p-trim-left-r 0 \
  --p-trunc-len-r 0 \
  --o-representative-sequences $PWD/qiime2_bushmeat/rep-seqs.qza \
  --o-table $PWD/qiime2_bushmeat/feature-table.qza \
  --o-denoising-stats $PWD/qiime2_bushmeat/stats.qza

echo "Summarizing denoise statistics"
qiime metadata tabulate \
  --m-input-file $PWD/qiime2_bushmeat/stats.qza \
  --o-visualization $PWD/qiime2_bushmeat/stats.qzv

## Visualizing denoise statistics
qiime tools view $PWD/qiime2_bushmeat/stats.qzv


echo ""
echo "Visualizing denoise statistics"
echo ""
qiime metadata tabulate \
  --m-input-file $PWD/qiime2_bushmeat/stats.qza \
  --o-visualization $PWD/qiime2_bushmeat/stats.qzv


echo ""
echo "Visualizing feature (sample & seqs) table"
echo ""
qiime feature-table summarize \
  --i-table $PWD/qiime2_bushmeat/feature-table.qza \
  --o-visualization $PWD/qiime2_bushmeat/feature-table.qzv \
  --m-sample-metadata-file $PWD/q2-metadata.tsv

echo ""
echo "Visualizing representative sequences"
echo ""
qiime feature-table tabulate-seqs \
  --i-data $PWD/qiime2_bushmeat/rep-seqs.qza \
  --o-visualization $PWD/qiime2_bushmeat/rep-seqs.qzv

echo ""
echo "Clustering sequences into OTUs"
echo ""


echo "De novo clustering"
# Sequences are clustered against one another. Here the clustering is performed at 99% to create 99% OTUs.
qiime vsearch cluster-features-de-novo \
  --i-table $PWD/qiime2_bushmeat/feature-table.qza \
  --i-sequences $PWD/qiime2_bushmeat/rep-seqs.qza \
  --p-perc-identity 0.99 \
  --o-clustered-table $PWD/qiime2_bushmeat/feature-table-dn-99.qza \
  --o-clustered-sequences $PWD/qiime2_bushmeat/rep-seqs-dn-99.qza

echo ""
echo "Visualizing denovo 99%"
echo ""
qiime feature-table tabulate-seqs \
  --i-data $PWD/qiime2_bushmeat/rep-seqs-dn-99.qza \
  --o-visualization $PWD/qiime2_bushmeat/rep-seqs-dn-99.qzv

echo ""
echo "Closed-reference clustering"
# Here the clustering is performed at 99% identity against the Greengenes 13_8 99% OTUs reference database.
qiime vsearch cluster-features-closed-reference \
  --i-table $PWD/qiime2_bushmeat/feature-table.qza \
  --i-sequences $PWD/qiime2_bushmeat/rep-seqs.qza \
  --i-reference-sequences $PWD/qiime2_bushmeat/rep-seqs-dn-99.qza \
  --p-perc-identity 0.99 \
  --o-clustered-table $PWD/qiime2_bushmeat/feature-table-cr-99.qza \
  --o-clustered-sequences $PWD/qiime2_bushmeat/rep-seqs-cr-99.qza \
  --o-unmatched-sequences $PWD/qiime2_bushmeat/unmatched-cr-99.qza

echo ""
echo "Open-reference clustering"
# Here the clustering is performed at 99% identity against the Greengenes 13_8 99% OTUs reference database.
qiime vsearch cluster-features-open-reference \
  --i-table $PWD/qiime2_bushmeat/feature-table.qza \
  --i-sequences $PWD/qiime2_bushmeat/rep-seqs.qza \
  --i-reference-sequences $PWD/qiime2_bushmeat/rep-seqs-dn-99.qza \
  --p-perc-identity 0.99 \
  --o-clustered-table $PWD/qiime2_bushmeat/feature-table-or-99.qza \
  --o-clustered-sequences $PWD/qiime2_bushmeat/rep-seqs-or-99.qza \
  --o-new-reference-sequences $PWD/qiime2_bushmeat/new-ref-seqs-or-99.qza


echo ""
echo "Performing de novo multiple sequence alignment of representative sequences using MAFFT " 
echo ""

qiime alignment mafft \
  --i-sequences $PWD/qiime2_bushmeat/rep-seqs.qza \
  --o-alignment $PWD/qiime2_bushmeat/aligned-rep-seqs.qza

echo ""
echo "Removing poor alignment" 
echo ""

qiime alignment mask \
  --i-alignment $PWD/qiime2_bushmeat/aligned-rep-seqs.qza \
  --o-masked-alignment $PWD/qiime2_bushmeat/masked-aligned-rep-seqs.qza

echo ""
echo "Visualizing masked alignments"
echo ""
qiime feature-table tabulate-seqs \
  --i-data $PWD/qiime2_bushmeat/masked-aligned-rep-seqs.qza \
  --o-visualization $PWD/qiime2_bushmeat/masked-aligned-rep-seqs.qzv


echo ""
echo "Phylogenetic sequence clustering" 
echo ""

echo "Unrooted tree"
echo ""
qiime phylogeny fasttree \
  --i-alignment $PWD/qiime2_bushmeat/masked-aligned-rep-seqs.qza \
  --o-tree $PWD/qiime2_bushmeat/unrooted-tree.qza

echo ""
echo "Rooted tree"
echo ""
qiime phylogeny midpoint-root \
  --i-tree $PWD/qiime2_bushmeat/unrooted-tree.qza \
  --o-rooted-tree $PWD/qiime2_bushmeat/rooted-tree.qza


echo ""
echo "Taxonomic assignment to masked aligned representative sequences"
echo ""

## Using Greengenes 2013-8-99-515-806-nb

time qiime feature-classifier classify-sklearn \
  --i-classifier $PWD/gg-13-8-99-515-806-nb-classifier.qza \
  --i-reads $PWD/qiime2_bushmeat/rep-seqs-dn-99.qza \
  --o-classification $PWD/qiime2_bushmeat/taxonomy.qza


### Visualizing taxonomy classification
qiime metadata tabulate \
  --m-input-file $PWD/qiime2_bushmeat/taxonomy.qza \
  --o-visualization $PWD/qiime2_bushmeat/taxonomy.qzv

echo ""
echo "QIIME2 data transformation"
echo ""

qiime tools export \
  --input-path $PWD/qiime2_bushmeat/feature-table.qza \
  --output-path $PWD/qiime2_bushmeat/q2-transformed-tables # Output feature-table.biom 


echo ""
echo "Converting BIOM table into Tab-Separated-Values (TSV)"
echo ""

biom convert \
  -i $PWD/qiime2_bushmeat/q2-transformed-tables/feature-table.biom \
  -o $PWD/qiime2_bushmeat/q2-transformed-tables/feature-table.tsv --to-tsv
  
qiime tools export \
  --input-path $PWD/qiime2_bushmeat/taxonomy.qza \
  --output-path $PWD/qiime2_bushmeat/q2-transformed-tables # Output taxonomy.tsv


echo ""
echo "Combining fetature table with taxonomy"
echo ""

qiime metadata tabulate \
  --m-input-file $PWD/qiime2_bushmeat/q2-transformed-tables/feature-table.tsv \
  --m-input-file $PWD/qiime2_bushmeat/q2-transformed-tables/taxonomy.tsv \
  --o-visualization $PWD/qiime2_bushmeat/q2-transformed-tables/feature-taxonomy-table.qzv


## Newick tree
qiime tools export \
  --input-path $PWD/qiime2_bushmeat/rooted-tree.qza \
  --output-path $PWD/qiime2_bushmeat/q2-transformed-tables/rooted-tree

qiime tools export \
  --input-path $PWD/qiime2_bushmeat/unrooted-tree.qza \
  --output-path $PWD/qiime2_bushmeat/q2-transformed-tables/unrooted-tree

#-------------------------
END=`date +%s`
RUNTIME=$(( END - START ))

echo ""
echo "Time taken to complete the whole workflow\n"
echo ""
echo "$RUNTIME seconds"

echo "...THE END..."

```

## Tidying qiime2 output
```{r}
taxlevels <- c("kingdom", "phylum", "class", "order", "family", "genus", "species")

read_delim("/Volumes/RedSeagate/MOTHUR_BUSHMEAT/SRR7450/qiime2_bushmeat/q2-transformed-tables/taxonomy.tsv", show_col_types = F) %>%
  rename_all(tolower) %>%
  rename(otu = "feature id") %>% 
  mutate(confidence = round(confidence, digits = 2)) %>%
  # filter(confidence == 1.00) %>% 
  mutate(taxon = str_replace_all(taxon, "; s__$", ""),
         taxon = str_replace_all(taxon, "; g__$", ""),
         taxon = str_replace_all(taxon, "; f__$", ""),
         taxon = str_replace_all(taxon, "; o__$", ""),
         taxon = str_replace_all(taxon, "; c__$", ""),
         taxon = str_replace_all(taxon, "; p__$", ""),
         taxon = str_replace_all(taxon, "; k__$", ""),
         ) %>% 
  separate(col = taxon, into = all_of(taxlevels), sep = "; ") %>%
  saveRDS("RDataRDS/q2_taxonomy.rds")
```

```{r}
read_delim("/Volumes/RedSeagate/MOTHUR_BUSHMEAT/SRR7450/qiime2_bushmeat/q2-transformed-tables/feature-table.tsv", skip = 1, show_col_types = F) %>%
  rename(otu = "#OTU ID") %>% 
  saveRDS("RDataRDS/q2_otutable.rds")

```

```{r}
readRDS("RDataRDS/q2_taxonomy.rds") %>% 
  inner_join(., readRDS("RDataRDS/q2_otutable.rds"), by="otu")
```

<br>
<br>

# Taxonomic Profiling Metagenomics Sequencing Data {#metaphlan-taxonomic-profiling}
## Using MetaPhlAn pipeline.
- We loop through the fastq files using the following parameters.
- You can optionally customize these parameters to suit your needs.
- Note that most parameters are default setting except the *-t rel_ab_w_read_stats* which will add the read count to the output.

```bash

for i in data/*.fastq.gz
	do 
		metaphlan $i \
		--input_type fastq \
		--force \
		--bowtie2db /Volumes/SeagateTMB/metaphlan_databases/ \
		--nproc 4 \
		--stat_q 0.02 \
		--min_mapq_val 5 \
		--output_file ${i%}_metaphlan3_profile.txt \
		--bowtie2out ${i%}_metaphlan3_bowtie2out.txt \
		--biom ${i%}_metaphlan3_abundance.biom \
    -t rel_ab_w_read_stats
	done

```

## Output of taxonomic profiling
- OTU table in mothur and QIIME2
- MetaPhlAn pipeline output taxonomic profiles for each input fastq file. 
- You can further use some integrated functions to manage the output. For example, the command below merge relative abundance into a single file similar to a transposed OTU table from Mothur and QIIME platforms.



