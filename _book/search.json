[{"path":"index.html","id":"frontpage","chapter":"Bioinformatics Analysis of Microbiome Data","heading":"Bioinformatics Analysis of Microbiome Data","text":"","code":""},{"path":"index.html","id":"quick-glimpse","chapter":"Bioinformatics Analysis of Microbiome Data","heading":"Quick Glimpse","text":"Investigating role microbial communities health disease requires thorough knowledge entire analytical process. Using wrong approaches can cost significant amount dollars lengthy process achieve desired results. PART 2 practical user guides intended provide analytical support microbiome research community. entire guide reproducible, allowing users easily follow along. interested, user may use model publish findings book format.","code":""},{"path":"index.html","id":"structure-of-this-guide","chapter":"Bioinformatics Analysis of Microbiome Data","heading":"Structure of this guide","text":"guide divided chapters facilitate easy navigation. chapter contains several sections displayed navigation bars left right. Click hyper-linked text want jump specific chapter section.","code":""},{"path":"index.html","id":"code-availability","chapter":"Bioinformatics Analysis of Microbiome Data","heading":"Code availability","text":"code available public GitHub repository. interested can request consulting service contacting developer repo using contact form.","code":""},{"path":"preprocess-16S-reads.html","id":"preprocess-16S-reads","chapter":"1 Preprocessing 16S rRNA Sequencing Data","heading":"1 Preprocessing 16S rRNA Sequencing Data","text":"point aware preprocessing bioinformatics tools needed getting started microbiome data analysis. assume tools already installed. Now time use :Get simple statistics.Check quality reads.Create summary report quality metrics.Trim poor read user-specified cutoff.Remove contaminants.","code":""},{"path":"preprocess-16S-reads.html","id":"original-read-statistics","chapter":"1 Preprocessing 16S rRNA Sequencing Data","heading":"1.1 Original read statistics","text":"Tool: SeqKit.","code":"mkdir -p data\nmkdir -p data/stats1  \nseqkit stat *.fastq.gz >data/stats1/seqkit_stats.txt"},{"path":"preprocess-16S-reads.html","id":"initial-read-quality-scores","chapter":"1 Preprocessing 16S rRNA Sequencing Data","heading":"1.2 Initial read quality scores","text":"Tool: FastQC","code":"mkdir data/fastqc1\nfastqc *.fastq.gz -o data/fastqc1"},{"path":"preprocess-16S-reads.html","id":"summary-of-initial-read-quality-scores","chapter":"1 Preprocessing 16S rRNA Sequencing Data","heading":"1.3 Summary of initial read quality scores","text":"Tool: MultQC.Plots multiqc exported multiqc_plots folder.Original: Mean quality scoresOriginal: Per sequence quality scores","code":"mkdir data/multiqc1\nmultiqc -f --data-dir data/fastqc1 -o data/multiqc1 --export"},{"path":"preprocess-16S-reads.html","id":"trimming-poor-reads","chapter":"1 Preprocessing 16S rRNA Sequencing Data","heading":"1.4 Trimming poor reads","text":"Using bbduk.sh bbmap platformWe use -Xmx4g switch tell Java much memory (heap size) use, demo 4 GB.Note use loop specify file name pattern look . files may contain different patterns containing R1_001.fastq.gz. use files downloaded NCBI-SRA looks like SRR7450758_1.fastq.gz.rerun seqkit stat, fastqc multiqc trimmed reads.Trimmed: Mean quality scoresTrimmed: Per sequence quality scores","code":"for i in `ls -1 *_1.fastq.gz | sed 's/_1.fastq.gz//'`\n  do\n  bbduk.sh -Xmx4g in1=$i\\_1.fastq.gz in2=$i\\_2.fastq.gz out1=data/trimmed/$i\\_1.fastq.gz out2=data/trimmed/$i\\_2.fastq.gz qtrim=r trimq=25 overwrite=True\n  donemkdir -p data/stats2  \nseqkit stat data/trimmed/*.fastq.gz >data/stats2/seqkit_stats.txt\n\nmkdir data/fastqc2\nfastqc data/trimmed/*.fastq.gz -o data/fastqc2\n\nmkdir data/multiqc2\nmultiqc -f --data-dir data/fastqc2 -o data/multiqc2 --export"},{"path":"preprocess-16S-reads.html","id":"read-decontamination","chapter":"1 Preprocessing 16S rRNA Sequencing Data","heading":"1.5 Read decontamination","text":"Using bbduk.sh trimmed reads.remove contamination (found), e.g.Â phiX Control reads.rerun seqkit stat, fastqc multiqc decontaminated reads.Decontaminated: Mean quality scoresDecontaminated: Per sequence quality scores","code":"for i in `ls -1 *_1.fastq.gz | sed 's/_1.fastq.gz//'`\ndo\nbbduk.sh -Xmx4g in1=data/trimmed/$i\\_1.fastq.gz in2=data/trimmed/$i\\_2.fastq.gz out1=data/decontam/$i\\_1.fastq.gz out2=data/decontam/$i\\_2.fastq.gz outm1=data/decontam/matchedphix/$i\\_1.fastq.gz outm2=data/decontam/matchedphix/$i\\_2.fastq.gz ref=~/bbmap/resources/phix174_ill.ref.fa.gz k=31 hdist=1 overwrite=True\ndonemkdir -p data/stats3  \nseqkit stat data/decontam/*.fastq.gz >data/stats3/seqkit_stats.txt\n\nmkdir data/fastqc3\nfastqc data/decontam/*.fastq.gz -o data/fastqc3\n\nmkdir data/multiqc3\nmultiqc -f --data-dir data/fastqc3 -o data/multiqc3 --export"},{"path":"preprocess-16S-reads.html","id":"merged-and-compare-preprocessed-reads","chapter":"1 Preprocessing 16S rRNA Sequencing Data","heading":"1.6 Merged and compare preprocessed reads","text":"","code":"\nlibrary(tidyverse, suppressPackageStartupMessages())\nlibrary(ggtext)\n\nstats1 <- read_table(\"data/stats1/seqkit_stats.txt\", show_col_types = F) %>% \n  mutate(file = str_replace_all(file, \".*/\", \"\")) %>% \n  select(file, original = num_seqs)\n\nstats2 <- read_table(\"data/stats2/seqkit_stats.txt\", show_col_types = F) %>% \n  mutate(file = str_replace_all(file, \".*/\", \"\")) %>% \n  select(file, trimmed = num_seqs)\n\nstats3 <- read_table(\"data/stats3/seqkit_stats.txt\", show_col_types = F) %>% \n  mutate(file = str_replace_all(file, \".*/\", \"\")) %>% \n  select(file, decontaminated = num_seqs)\n\ninner_join(stats1, stats2, by = \"file\") %>% \n  inner_join(., stats3, by = \"file\") %>% \n  mutate(strand = ifelse(str_detect(file, \"_1\"), \"foward\", \"reverse\"), .before=original) %>%\n  pivot_longer(cols = -c(file, strand), names_to = \"variable\", values_to = \"num_seqs\") %>% \n  mutate(variable = factor(variable),\n         variable = fct_reorder(variable, num_seqs, .desc=TRUE)) %>% \n  ggplot(aes(x = strand, y = num_seqs/1000, fill = variable)) +\n  geom_col(position = \"dodge\") +\n  labs(x = \"Read Strand\", y = \"Number of Reads (thousand)\", fill = \"Preprocess\") +\n  theme_classic() +\n  theme(axis.text.x = element_markdown(),\n        legend.text = element_text(face = NULL),\n        legend.key.size = unit(12, \"pt\")) + \n  scale_y_continuous(expand = c(0, 0))"},{"path":"preprocess-kneaddata.html","id":"preprocess-kneaddata","chapter":"2 Preprocessing Metagenomics Sequencing Data","heading":"2 Preprocessing Metagenomics Sequencing Data","text":"","code":""},{"path":"preprocess-kneaddata.html","id":"getting-initial-read-statistics","chapter":"2 Preprocessing Metagenomics Sequencing Data","heading":"2.1 Getting initial read statistics","text":"","code":"mkdir -p kneaddata\nmkdir -p kneaddata/stats1  \nseqkit stat *.fastq.gz >kneaddata/stats1/seqkit_stats.txt"},{"path":"preprocess-kneaddata.html","id":"initial-read-quality-scores-1","chapter":"2 Preprocessing Metagenomics Sequencing Data","heading":"2.2 Initial read quality scores","text":"Using KneadData tool biobakery.kneaddata tool exclusively used preprocess metagenomics data.set run fastqc compute initial quality checks.summarize fastqc results outside KneadData pipeline using multiqc software.","code":"for i in data/*.fastq.gz\ndo\ntime kneaddata --i $i \\\n-o kneaddata/fastqc1 \\\n--run-fastqc-start \\\n--bypass-trim \\\n--bypass-trf \\\n--sequencer-source \"none\" \\\n-t 4 \ndonemkdir -p kneaddata/multiqc1\nmultiqc -f --data-dir kneaddata/fastqc1 -o kneaddata/multiqc1 --export"},{"path":"preprocess-kneaddata.html","id":"read-trimming","chapter":"2 Preprocessing Metagenomics Sequencing Data","heading":"2.3 Read Trimming","text":"Using trimmomatic tool trim poor reads.fastqc function automatically run trimming.run seqkit multiqc trimmed reads","code":"for i in data/*.fastq.gz\ndo\n  time kneaddata --i $i \\\n    -o kneaddata/fastqc2 \\\n    --trimmomatic /Users/tmbuza/opt/anaconda3/envs/biobakery3/bin/ \\\n    --trimmomatic-options \\\n        \"ILLUMINACLIP:/Volumes/SeagateTMB/trimmomatic-0.36/adapters/NexteraPE-PE.fa:2:30:10 \\\n        LEADING:3 \\\n        TRAILING:3 \\\n        SLIDINGWINDOW:4:20 \\\n        MINLEN:60\" \\\n    --sequencer-source \"NexteraPE\" \\\n    --run-fastqc-end \\\n    --bypass-trf \\\n    -t 4 \ndonemkdir -p kneaddata/stats2\nseqkit stat kneaddata/fastqc2/*trimmed.fastq >kneaddata/stats2/seqkit_stats.txt\n\nmkdir -p kneaddata/multiqc2\nmultiqc -f --data-dir kneaddata/fastqc2 -o kneaddata/multiqc2 --export"},{"path":"preprocess-kneaddata.html","id":"read-decontamination-1","chapter":"2 Preprocessing Metagenomics Sequencing Data","heading":"2.4 Read Decontamination","text":"","code":""},{"path":"preprocess-kneaddata.html","id":"option-1-searching-against-bowtie2-database","chapter":"2 Preprocessing Metagenomics Sequencing Data","heading":"2.4.1 Option 1: Searching against Bowtie2 database","text":"Trimming done first using trimmomatic.contaminated reads identified searching reads bowtie2 reference database.fastqc automatically run decontamination.run seqkit multiqc decontaminated reads","code":"for i in data/*.fastq.gz\ndo\ntime kneaddata --i $i \\\n  -o kneaddata/fastqc3 \\\n      --reference-db /Volumes/SeagateTMB/kneaddata_database/ \\\n      --trimmomatic /Users/tmbuza/opt/anaconda3/envs/biobakery3/bin/ \\\n      --trimmomatic-options \\\n          \"ILLUMINACLIP:/Volumes/SeagateTMB/trimmomatic-0.36/adapters/NexteraPE-PE.fa:2:30:10 \\\n          LEADING:3 \\\n          TRAILING:3 \\\n          SLIDINGWINDOW:4:20 \\\n          MINLEN:60\" \\\n      --sequencer-source \"NexteraPE\" \\\n      --run-trf \\\n      --run-fastqc-end \\\n      -t 4 \ndonemkdir -p kneaddata/stats3\nseqkit stat kneaddata/fastqc3/*trimmed.fastq >kneaddata/stats3/seqkit_stats.txt\n\nmkdir -p kneaddata/multiqc3\nmultiqc -f --data-dir kneaddata/fastqc3 -o kneaddata/multiqc3 --export"},{"path":"preprocess-kneaddata.html","id":"option-2-seaching-against-bmtagger-database","chapter":"2 Preprocessing Metagenomics Sequencing Data","heading":"2.4.2 Option 2: Seaching against BMTagger database","text":"Trimming done first using trimmomatic.contaminated reads identified searching reads BMTagger database.fastqc automatically run decontamination.run seqkit multiqc decontaminated reads","code":"mkdir kneaddata\nfor i in data/*.fastq.gz\ndo\ntime kneaddata --i $i \\\n  -o kneaddata/fastqc4 \\\n      --reference-db /Volumes/SeagateTMB/Human_Assembly19_BMTagger_DB/ \\\n      --trimmomatic /Users/tmbuza/opt/anaconda3/envs/biobakery3/bin/ \\\n      --trimmomatic-options \\\n          \"ILLUMINACLIP:/Volumes/SeagateTMB/trimmomatic-0.36/adapters/NexteraPE-PE.fa:2:30:10 \\\n          LEADING:3 \\\n          TRAILING:3 \\\n          SLIDINGWINDOW:4:20 \\\n          MINLEN:60\" \\\n      --sequencer-source \"NexteraPE\" \\\n      --run-trf \\\n      --run-bmtagger \\\n      --run-fastqc-end \\\n      -t 4 \ndonemkdir -p kneaddata/stats4\nseqkit stat kneaddata/fastqc4/*trimmed.fastq >kneaddata/stats4/seqkit_stats.txt\n\nmkdir -p kneaddata/multiqc4\nmultiqc -f --data-dir kneaddata/fastqc4 -o kneaddata/multiqc4 --export"},{"path":"mothur-pipeline.html","id":"mothur-pipeline","chapter":"3 Mcrobial profiling Using mothur","heading":"3 Mcrobial profiling Using mothur","text":"","code":""},{"path":"mothur-pipeline.html","id":"expected-tabulated-results","chapter":"3 Mcrobial profiling Using mothur","heading":"3.1 Expected tabulated results","text":"Operational Taxonomic Units (OTUs).Amplicon Sequence Variants (ASVs).Phylotypes.Conserved taxonomy.","code":""},{"path":"mothur-pipeline.html","id":"download-trained-classifer","chapter":"3 Mcrobial profiling Using mothur","heading":"3.2 Download trained classifer","text":"demo purposes use Silva seed due smaller size.mothur-based classifiers can found .","code":"wget https://mothur.s3.us-east-2.amazonaws.com/wiki/silva.seed_v138_1.tgz\ntar xvzf silva.seed_v138_1.tgz\nrm *.tgz"},{"path":"mothur-pipeline.html","id":"implementing-mothur-pipeline-interactively","chapter":"3 Mcrobial profiling Using mothur","heading":"3.3 Implementing mothur pipeline interactively","text":"recommend familiarize tutorials detailed MiSeq SOP.\nRun analysis mothur command line bash. takes advantage using current option refer last saved files.\n\ngenerating mapping file automatically make sure confer accepted format mothur_mapping_files.tsv described previous section.\n\ndemo name mapping file bush.files. means output files prefixed term bush reflect name project. Try avoid longer names.\nLetâs get started! Start running one line time see goes. See another option end script.Alternatively,can save code mothur_code.batch place folder named code.call mothur run file bash command line shown .","code":"set.current(processors=1)\n# set.logfile(name=make_files.logfile)\n# make.file(inputdir=., type=fastq.gz, prefix=test)\n\nset.logfile(name=seq_assembly.logfile)\nmake.contigs(file=bush.files, outputdir=./test, maxambig=0, maxlength=275);\nunique.seqs(count=current);\nsummary.seqs(fasta=current, count=current)\n\nset.logfile(name=seq_align_preclustering.logfile)\nalign.seqs(fasta=current, reference=silva.seed_v138_1.align);\nscreen.seqs(fasta=current, count=current, start=13862, end=23444, maxhomop=8);\nfilter.seqs(fasta=current, vertical=T, trump=.);\npre.cluster(fasta=current, count=current, diffs=2);\nunique.seqs(fasta=current, count=current);\n\nset.logfile(name=chimera_removal.logfile)\nchimera.vsearch(fasta=current, count=current, dereplicate=t);\n\nset.logfile(name=silva_seed_classification.logfile)\nclassify.seqs(fasta=current, count=current, reference=silva.seed_v138_1.align, taxonomy=silva.seed_v138_1.tax, cutoff=100);\nremove.lineage(fasta=current, count=current, taxonomy=current, taxon=Chloroplast-Mitochondria-unknown-Archaea-Eukaryota);\n\nset.logfile(name=final_files.logfile)\nrename.file(fasta=current, count=current, taxonomy=current, prefix=final)\n\nset.logfile(name=otu_clustering.logfile)\ndist.seqs(fasta=current, cutoff=0.03);\ncluster(column=current, count=current, cutoff=0.03);\nmake.shared(list=current, count=current, label=0.03);\nclassify.otu(list=current, count=current, taxonomy=current, label=0.03);\nmake.lefse(shared=current, constaxonomy=current);\nmake.biom(shared=current, constaxonomy=current);\n\nset.logfile(name=phylotype_clustering.logfile)\nphylotype(taxonomy=current);\nmake.shared(list=current, count=current, label=1);\nclassify.otu(list=current, count=current, taxonomy=current, label=1);\nmake.lefse(shared=current, constaxonomy=current);\nmake.biom(shared=current, constaxonomy=current);\n\nset.logfile(name=asv_clustering.logfile)\nmake.shared(count=current)\nclassify.otu(list=current, count=current, taxonomy=current, label=ASV)\nmake.lefse(shared=current, constaxonomy=current)\nmake.biom(shared=current, constaxonomy=current)\n\nset.logfile(name=phylogenetic_clustering.logfile)\ndist.seqs(fasta=current, output=lt)\nclearcut(phylip=current)mothur code/mothur_code.batch # if mothur is in the path\n./mothur code/mothur_code.batch # on mac/linux if the executable `mothur` is in the working directory.\n./mothur.exe code/mothur_code.batch # on Windows machins if the executable `mothur.exe` is in the working directory."},{"path":"qiime2-pipeline.html","id":"qiime2-pipeline","chapter":"4 Mcrobial Profiling Using qiime2","heading":"4 Mcrobial Profiling Using qiime2","text":"","code":""},{"path":"qiime2-pipeline.html","id":"expected-tabulated-results-1","chapter":"4 Mcrobial Profiling Using qiime2","heading":"4.1 Expected tabulated results","text":"Operational Taxonomic Units (OTUs).Taxonomy.","code":""},{"path":"qiime2-pipeline.html","id":"prerequisites","chapter":"4 Mcrobial Profiling Using qiime2","heading":"4.2 Prerequisites","text":"","code":""},{"path":"qiime2-pipeline.html","id":"download-a-qiime2-trained-classifer","chapter":"4 Mcrobial Profiling Using qiime2","heading":"4.2.1 Download a QIIME2 trained classifer","text":"can use Naive Bayes (nb) classifiers trained GreenGenes SILVA database 99% OTUs. can train classifier using q2-feature-classifier.download smallest classifier, naive classifier trained Greengenes 13_8 99% OTUs 515F/806R region sequences","code":"wget \\\n  -O \"gg-13-8-99-515-806-nb-classifier.qza\" \\\n  \"https://data.qiime2.org/2022.2/common/gg-13-8-99-515-806-nb-classifier.qza\""},{"path":"qiime2-pipeline.html","id":"install-qiime2","chapter":"4 Mcrobial Profiling Using qiime2","heading":"4.2.2 Install qiime2","text":"assumes already installed QIIME 2. please using instructions described !. simple demo installing qiime2 Mac OS.","code":"wget https://data.qiime2.org/distro/core/qiime2-2022.2-py38-osx-conda.yml\nconda env create -n qiime2-2022.2 --file qiime2-2022.2-py38-osx-conda.yml\nrm qiime2-2022.2-py39-osx-conda.yml"},{"path":"qiime2-pipeline.html","id":"running-qiime2-commands","chapter":"4 Mcrobial Profiling Using qiime2","heading":"4.2.3 Running QIIME2 commands","text":"prefer use command line interface g2cli.Activate qiime2 environment: using qiime2-2022.2.","code":""},{"path":"qiime2-pipeline.html","id":"activate-qiime-environment","chapter":"4 Mcrobial Profiling Using qiime2","heading":"4.2.4 Activate qiime environment","text":"","code":"conda activate qiime2-2022.2"},{"path":"qiime2-pipeline.html","id":"confirm-installation","chapter":"4 Mcrobial Profiling Using qiime2","heading":"4.2.5 Confirm installation","text":"","code":"qiime info"},{"path":"qiime2-pipeline.html","id":"validate-associated-metadata","chapter":"4 Mcrobial Profiling Using qiime2","heading":"4.2.6 Validate associated metadata","text":"","code":"qiime tools inspect-metadata \\\n  $PWD/q2-metadata.tsv"},{"path":"qiime2-pipeline.html","id":"tabulate-metadata-in-qiime2-format","chapter":"4 Mcrobial Profiling Using qiime2","heading":"4.2.7 Tabulate metadata in QIIME2 format","text":"","code":"qiime metadata tabulate \\\n  --m-input-file $PWD/q2-metadata.tsv \\\n  --o-visualization $PWD/qiime2_bushmeat/sample-metadata.qzv"},{"path":"qiime2-pipeline.html","id":"visualizing-tabulated-metadata","chapter":"4 Mcrobial Profiling Using qiime2","heading":"4.2.8 Visualizing tabulated metadata","text":"","code":"qiime tools view $PWD/qiime2_bushmeat/sample-metadata.qzv"},{"path":"qiime2-pipeline.html","id":"import-paired-end-fastq-files","chapter":"4 Mcrobial Profiling Using qiime2","heading":"4.3 Import paired-end fastq files","text":"","code":"qiime tools import \\\n  --type 'SampleData[PairedEndSequencesWithQuality]' \\\n  --input-path $PWD/pe-33-manifest.tsv \\\n  --output-path $PWD/qiime2_bushmeat/demux.qza \\\n  --input-format PairedEndFastqManifestPhred33V2"},{"path":"qiime2-pipeline.html","id":"summarize-and-visualize-preliminary-analysis","chapter":"4 Mcrobial Profiling Using qiime2","heading":"4.3.1 Summarize and visualize preliminary analysis","text":"Review pick truncation parameters needed.","code":"qiime demux summarize \\\n  --i-data $PWD/qiime2_bushmeat/demux.qza \\\n  --o-visualization $PWD/qiime2_bushmeat/demux.qzvqiime tools view $PWD/qiime2_bushmeat/demux.qzv"},{"path":"qiime2-pipeline.html","id":"microbial-profiling-pipeline","chapter":"4 Mcrobial Profiling Using qiime2","heading":"4.4 Microbial profiling pipeline","text":"can set parameters desired.Note may take , please patient.addition setting STAR END time, also optionally use time gauge amount time used analysis.","code":"time qiime dada2 denoise-paired \\\n  --i-demultiplexed-seqs $PWD/qiime2_bushmeat/demux.qza \\\n  --p-trim-left-f 0 \\\n  --p-trunc-len-f 0 \\\n  --p-trim-left-r 0 \\\n  --p-trunc-len-r 0 \\\n  --o-representative-sequences $PWD/qiime2_bushmeat/rep-seqs.qza \\\n  --o-table $PWD/qiime2_bushmeat/feature-table.qza \\\n  --o-denoising-stats $PWD/qiime2_bushmeat/stats.qza\n\necho \"Summarizing denoise statistics\"\nqiime metadata tabulate \\\n  --m-input-file $PWD/qiime2_bushmeat/stats.qza \\\n  --o-visualization $PWD/qiime2_bushmeat/stats.qzv\n\n## Visualizing denoise statistics\nqiime tools view $PWD/qiime2_bushmeat/stats.qzv\n\n\necho \"\"\necho \"Visualizing denoise statistics\"\necho \"\"\nqiime metadata tabulate \\\n  --m-input-file $PWD/qiime2_bushmeat/stats.qza \\\n  --o-visualization $PWD/qiime2_bushmeat/stats.qzv\n\n\necho \"\"\necho \"Visualizing feature (sample & seqs) table\"\necho \"\"\nqiime feature-table summarize \\\n  --i-table $PWD/qiime2_bushmeat/feature-table.qza \\\n  --o-visualization $PWD/qiime2_bushmeat/feature-table.qzv \\\n  --m-sample-metadata-file $PWD/q2-metadata.tsv\n\necho \"\"\necho \"Visualizing representative sequences\"\necho \"\"\nqiime feature-table tabulate-seqs \\\n  --i-data $PWD/qiime2_bushmeat/rep-seqs.qza \\\n  --o-visualization $PWD/qiime2_bushmeat/rep-seqs.qzv\n\necho \"\"\necho \"Clustering sequences into OTUs\"\necho \"\"\n\n\necho \"De novo clustering\"\n# Sequences are clustered against one another. Here the clustering is performed at 99% to create 99% OTUs.\nqiime vsearch cluster-features-de-novo \\\n  --i-table $PWD/qiime2_bushmeat/feature-table.qza \\\n  --i-sequences $PWD/qiime2_bushmeat/rep-seqs.qza \\\n  --p-perc-identity 0.99 \\\n  --o-clustered-table $PWD/qiime2_bushmeat/feature-table-dn-99.qza \\\n  --o-clustered-sequences $PWD/qiime2_bushmeat/rep-seqs-dn-99.qza\n\necho \"\"\necho \"Visualizing denovo 99%\"\necho \"\"\nqiime feature-table tabulate-seqs \\\n  --i-data $PWD/qiime2_bushmeat/rep-seqs-dn-99.qza \\\n  --o-visualization $PWD/qiime2_bushmeat/rep-seqs-dn-99.qzv\n\necho \"\"\necho \"Closed-reference clustering\"\n# Here the clustering is performed at 99% identity against the Greengenes 13_8 99% OTUs reference database.\nqiime vsearch cluster-features-closed-reference \\\n  --i-table $PWD/qiime2_bushmeat/feature-table.qza \\\n  --i-sequences $PWD/qiime2_bushmeat/rep-seqs.qza \\\n  --i-reference-sequences $PWD/qiime2_bushmeat/rep-seqs-dn-99.qza \\\n  --p-perc-identity 0.99 \\\n  --o-clustered-table $PWD/qiime2_bushmeat/feature-table-cr-99.qza \\\n  --o-clustered-sequences $PWD/qiime2_bushmeat/rep-seqs-cr-99.qza \\\n  --o-unmatched-sequences $PWD/qiime2_bushmeat/unmatched-cr-99.qza\n\necho \"\"\necho \"Open-reference clustering\"\n# Here the clustering is performed at 99% identity against the Greengenes 13_8 99% OTUs reference database.\nqiime vsearch cluster-features-open-reference \\\n  --i-table $PWD/qiime2_bushmeat/feature-table.qza \\\n  --i-sequences $PWD/qiime2_bushmeat/rep-seqs.qza \\\n  --i-reference-sequences $PWD/qiime2_bushmeat/rep-seqs-dn-99.qza \\\n  --p-perc-identity 0.99 \\\n  --o-clustered-table $PWD/qiime2_bushmeat/feature-table-or-99.qza \\\n  --o-clustered-sequences $PWD/qiime2_bushmeat/rep-seqs-or-99.qza \\\n  --o-new-reference-sequences $PWD/qiime2_bushmeat/new-ref-seqs-or-99.qza\n\n\necho \"\"\necho \"Performing de novo multiple sequence alignment of representative sequences using MAFFT \" \necho \"\"\n\nqiime alignment mafft \\\n  --i-sequences $PWD/qiime2_bushmeat/rep-seqs.qza \\\n  --o-alignment $PWD/qiime2_bushmeat/aligned-rep-seqs.qza\n\necho \"\"\necho \"Removing poor alignment\" \necho \"\"\n\nqiime alignment mask \\\n  --i-alignment $PWD/qiime2_bushmeat/aligned-rep-seqs.qza \\\n  --o-masked-alignment $PWD/qiime2_bushmeat/masked-aligned-rep-seqs.qza\n\necho \"\"\necho \"Visualizing masked alignments\"\necho \"\"\nqiime feature-table tabulate-seqs \\\n  --i-data $PWD/qiime2_bushmeat/masked-aligned-rep-seqs.qza \\\n  --o-visualization $PWD/qiime2_bushmeat/masked-aligned-rep-seqs.qzv\n\n\necho \"\"\necho \"Phylogenetic sequence clustering\" \necho \"\"\n\necho \"Unrooted tree\"\necho \"\"\nqiime phylogeny fasttree \\\n  --i-alignment $PWD/qiime2_bushmeat/masked-aligned-rep-seqs.qza \\\n  --o-tree $PWD/qiime2_bushmeat/unrooted-tree.qza\n\necho \"\"\necho \"Rooted tree\"\necho \"\"\nqiime phylogeny midpoint-root \\\n  --i-tree $PWD/qiime2_bushmeat/unrooted-tree.qza \\\n  --o-rooted-tree $PWD/qiime2_bushmeat/rooted-tree.qza\n\n\necho \"\"\necho \"Taxonomic assignment to masked aligned representative sequences\"\necho \"\"\n\n## Using Greengenes 2013-8-99-515-806-nb\n\ntime qiime feature-classifier classify-sklearn \\\n  --i-classifier $PWD/gg-13-8-99-515-806-nb-classifier.qza \\\n  --i-reads $PWD/qiime2_bushmeat/rep-seqs-dn-99.qza \\\n  --o-classification $PWD/qiime2_bushmeat/taxonomy.qza\n\n\n### Visualizing taxonomy classification\nqiime metadata tabulate \\\n  --m-input-file $PWD/qiime2_bushmeat/taxonomy.qza \\\n  --o-visualization $PWD/qiime2_bushmeat/taxonomy.qzv\n\necho \"\"\necho \"QIIME2 data transformation\"\necho \"\"\n\nqiime tools export \\\n  --input-path $PWD/qiime2_bushmeat/feature-table.qza \\\n  --output-path $PWD/qiime2_bushmeat/q2-transformed-tables # Output feature-table.biom \n\n\necho \"\"\necho \"Converting BIOM table into Tab-Separated-Values (TSV)\"\necho \"\"\n\nbiom convert \\\n  -i $PWD/qiime2_bushmeat/q2-transformed-tables/feature-table.biom \\\n  -o $PWD/qiime2_bushmeat/q2-transformed-tables/feature-table.tsv --to-tsv\n  \nqiime tools export \\\n  --input-path $PWD/qiime2_bushmeat/taxonomy.qza \\\n  --output-path $PWD/qiime2_bushmeat/q2-transformed-tables # Output taxonomy.tsv\n\n\necho \"\"\necho \"Combining fetature table with taxonomy\"\necho \"\"\n\nqiime metadata tabulate \\\n  --m-input-file $PWD/qiime2_bushmeat/q2-transformed-tables/feature-table.tsv \\\n  --m-input-file $PWD/qiime2_bushmeat/q2-transformed-tables/taxonomy.tsv \\\n  --o-visualization $PWD/qiime2_bushmeat/q2-transformed-tables/feature-taxonomy-table.qzv\n\n\n## Newick tree\nqiime tools export \\\n  --input-path $PWD/qiime2_bushmeat/rooted-tree.qza \\\n  --output-path $PWD/qiime2_bushmeat/q2-transformed-tables/rooted-tree\n\nqiime tools export \\\n  --input-path $PWD/qiime2_bushmeat/unrooted-tree.qza \\\n  --output-path $PWD/qiime2_bushmeat/q2-transformed-tables/unrooted-tree"},{"path":"qiime2-pipeline.html","id":"getting-tidy-otus-and-taxonomy","chapter":"4 Mcrobial Profiling Using qiime2","heading":"4.5 Getting tidy OTUs and taxonomy","text":"","code":"\ntaxlevels <- c(\"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\")\n\nread_delim(\"data/q2-transformed-tables/taxonomy.tsv\", show_col_types = F) %>%\n  rename_all(tolower) %>%\n  rename(otu = \"feature id\") %>% \n  mutate(confidence = round(confidence, digits = 2)) %>%\n  # filter(confidence == 1.00) %>% \n  mutate(taxon = str_replace_all(taxon, \"; s__$\", \"\"),\n         taxon = str_replace_all(taxon, \"; g__$\", \"\"),\n         taxon = str_replace_all(taxon, \"; f__$\", \"\"),\n         taxon = str_replace_all(taxon, \"; o__$\", \"\"),\n         taxon = str_replace_all(taxon, \"; c__$\", \"\"),\n         taxon = str_replace_all(taxon, \"; p__$\", \"\"),\n         taxon = str_replace_all(taxon, \"; k__$\", \"\"),\n         ) %>% \n  separate(col = taxon, into = all_of(taxlevels), sep = \"; \") %>%\n  saveRDS(\"RDataRDS/q2_taxonomy.rds\")\nread_delim(\"data/q2-transformed-tables/feature-table.tsv\", skip = 1, show_col_types = F) %>%\n  rename(otu = \"#OTU ID\") %>% \n  saveRDS(\"RDataRDS/q2_otutable.rds\")\nreadRDS(\"RDataRDS/q2_taxonomy.rds\") %>% \n  inner_join(., readRDS(\"RDataRDS/q2_otutable.rds\"), by=\"otu\")# A tibble: 494 Ã 19\n   otu     kingdom phylum class order family genus species confidence SRR7450728\n   <chr>   <chr>   <chr>  <chr> <chr> <chr>  <chr> <chr>        <dbl>      <dbl>\n 1 04edaaâ¦ k__Bacâ¦ p__Fiâ¦ c__Câ¦ o__Câ¦ f__Peâ¦ g__[â¦ s__sorâ¦       0.96        267\n 2 e27b9eâ¦ k__Bacâ¦ p__Fiâ¦ c__Bâ¦ o__Bâ¦ f__Stâ¦ g__Mâ¦ s__casâ¦       0.91      15210\n 3 d46e22â¦ k__Bacâ¦ p__Prâ¦ c__Gâ¦ o__Eâ¦ f__Enâ¦ <NA>  <NA>          1          2374\n 4 41db43â¦ k__Bacâ¦ <NA>   <NA>  <NA>  <NA>   <NA>  <NA>          0.93        409\n 5 9580aaâ¦ k__Bacâ¦ p__Fiâ¦ c__Câ¦ o__Câ¦ f__Clâ¦ g__Câ¦ s__perâ¦       1           146\n 6 6f70e5â¦ k__Bacâ¦ p__Fiâ¦ c__Câ¦ o__Câ¦ f__Clâ¦ g__Câ¦ <NA>          0.8           0\n 7 547357â¦ k__Bacâ¦ <NA>   <NA>  <NA>  <NA>   <NA>  <NA>          0.97       7092\n 8 bc3621â¦ k__Bacâ¦ p__Prâ¦ c__Gâ¦ o__Pâ¦ f__Moâ¦ g__Aâ¦ <NA>          1           357\n 9 9209e4â¦ k__Bacâ¦ p__Fiâ¦ c__Câ¦ o__Câ¦ f__Clâ¦ g__Câ¦ <NA>          0.98        689\n10 5970d8â¦ k__Bacâ¦ p__Cyâ¦ c__Câ¦ o__Câ¦ <NA>   <NA>  <NA>          1           111\n# â¦ with 484 more rows, and 9 more variables: SRR7450732 <dbl>,\n#   SRR7450746 <dbl>, SRR7450747 <dbl>, SRR7450752 <dbl>, SRR7450753 <dbl>,\n#   SRR7450755 <dbl>, SRR7450757 <dbl>, SRR7450758 <dbl>, SRR7450759 <dbl>"},{"path":"metaphlan-taxonomic-profiling.html","id":"metaphlan-taxonomic-profiling","chapter":"5 Taxonomic Profiling of Metagenomics Sequencing Data","heading":"5 Taxonomic Profiling of Metagenomics Sequencing Data","text":"","code":""},{"path":"metaphlan-taxonomic-profiling.html","id":"expected-tabulated-results-2","chapter":"5 Taxonomic Profiling of Metagenomics Sequencing Data","heading":"5.1 Expected tabulated results","text":"Relative taxonomic profiles taxonomy orRelative taxonomic profiles read count taxonomy setting -t rel_ab_w_read_stats.","code":""},{"path":"metaphlan-taxonomic-profiling.html","id":"using-metaphlan-pipeline.","chapter":"5 Taxonomic Profiling of Metagenomics Sequencing Data","heading":"5.2 Using MetaPhlAn pipeline.","text":"loop fastq files using following parameters.can optionally customize parameters suit needs.Note parameters default setting except -t rel_ab_w_read_stats add read count output.","code":"for i in data/*.fastq.gz\n    do \n        metaphlan $i \\\n        --input_type fastq \\\n        --force \\\n        --bowtie2db /Volumes/SeagateTMB/metaphlan_databases/ \\\n        --nproc 4 \\\n        --stat_q 0.02 \\\n        --min_mapq_val 5 \\\n        --output_file ${i%}_metaphlan3_profile.txt \\\n        --bowtie2out ${i%}_metaphlan3_bowtie2out.txt \\\n        --biom ${i%}_metaphlan3_abundance.biom \\\n    -t rel_ab_w_read_stats\n    done"},{"path":"saved-data-objects.html","id":"saved-data-objects","chapter":"A Saved Data Objects","heading":"A Saved Data Objects","text":"","code":""},{"path":"saved-data-objects.html","id":"rds-format-for-individual-object","chapter":"A Saved Data Objects","heading":"A.1 RDS Format for Individual Object","text":"","code":"[1] \"./RDataRDS/metadata.rds\"     \"./RDataRDS/q2_otutable.rds\" \n[3] \"./RDataRDS/q2_taxonomy.rds\"  \"./RDataRDS/seqkit_stats.rds\""},{"path":"saved-data-objects.html","id":"rdata-format-for-multiple-objects","chapter":"A Saved Data Objects","heading":"A.2 RData Format for Multiple Objects","text":"","code":"[1] \"./RDataRDS/saved_objects.RData\""},{"path":"saved-data-objects.html","id":"csv-or-tsv-format-files","chapter":"A Saved Data Objects","heading":"A.3 CSV or TSV Format Files","text":"","code":" [1] \"./data/animal.tsv\"               \"./data/bases.tsv\"               \n [3] \"./data/bushmeat_metadata.csv\"    \"./data/metadata.tsv\"            \n [5] \"./data/mothur_mapping_file.tsv\"  \"./data/mothur_mapping_files.tsv\"\n [7] \"./data/mothur_metadata.tsv\"      \"./data/pe-33-manifest.tsv\"      \n [9] \"./data/q2_dada2_qc.tsv\"          \"./data/q2-metadata.tsv\"         \n[11] \"./data/q2-pe-33-manifest.tsv\"   "},{"path":"saved-data-objects.html","id":"how-to-reload-rds-or-rdata-into-r-environment","chapter":"A Saved Data Objects","heading":"A.4 How to reload RDS or RData into R environment","text":"\nRDS format e.g.Â foo.rds\n\nfoo <- readRDS(âRDataRDS/foo.rdsâ)\n\n\nfoo <- readRDS(âRDataRDS/foo.rdsâ)\n\nRData format e.g.Â foo.RData\n\nload(âRDataRDS/foo.RDataâ, verbose = TRUE)\n\n\nload(âRDataRDS/foo.RDataâ, verbose = TRUE)\n\nList objects RData\n\nlsdata(âfoo.RDataâ)\n\n\nlsdata(âfoo.RDataâ)\n","code":""},{"path":"software-and-packages.html","id":"software-and-packages","chapter":"B Software and Packages","heading":"B Software and Packages","text":"","code":""},{"path":"software-and-packages.html","id":"basic-dependencies","chapter":"B Software and Packages","heading":"B.1 Basic dependencies","text":"R version 4.1.3 (2022-03-10)tidyverse (v. 1.3.1)knitr (v. 1.38)rmarkdown (v. 2.13)bookdown (v. 0.25)","code":""},{"path":"software-and-packages.html","id":"available-on-machine-used","chapter":"B Software and Packages","heading":"B.2 Available on machine used","text":"","code":"R version 4.1.3 (2022-03-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur/Monterey 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] DiagrammeRsvg_0.1 DiagrammeR_1.0.9  cgwtools_3.3      metagMisc_0.0.4  \n [5] dendextend_1.15.2 ggtext_0.1.1      ape_5.6-2         phyloseq_1.38.0  \n [9] downlit_0.4.0     ggpubr_0.4.0      bookdown_0.25     rmarkdown_2.13   \n[13] knitr_1.38        forcats_0.5.1     stringr_1.4.0     dplyr_1.0.8      \n[17] purrr_0.3.4       readr_2.1.2       tidyr_1.2.0       tibble_3.1.6     \n[21] ggplot2_3.3.5     tidyverse_1.3.1  \n\nloaded via a namespace (and not attached):\n  [1] colorspace_2.0-3       ggsignif_0.6.3         ellipsis_0.3.2        \n  [4] markdown_1.1           XVector_0.34.0         fs_1.5.2              \n  [7] gridtext_0.1.4         rstudioapi_0.13        farver_2.1.0          \n [10] bit64_4.0.5            fansi_1.0.3            lubridate_1.8.0       \n [13] xml2_1.3.3             codetools_0.2-18       splines_4.1.3         \n [16] cachem_1.0.6           ade4_1.7-18            jsonlite_1.8.0        \n [19] broom_0.7.12           cluster_2.1.2          dbplyr_2.1.1          \n [22] compiler_4.1.3         httr_1.4.2             backports_1.4.1       \n [25] assertthat_0.2.1       Matrix_1.4-1           fastmap_1.1.0         \n [28] cli_3.2.0              visNetwork_2.1.0       htmltools_0.5.2       \n [31] tools_4.1.3            gmp_0.6-5              igraph_1.2.11         \n [34] gtable_0.3.0           glue_1.6.2             GenomeInfoDbData_1.2.7\n [37] reshape2_1.4.4         rsvg_2.3.1             V8_4.1.0              \n [40] Rcpp_1.0.8.3           carData_3.0-5          Biobase_2.54.0        \n [43] cellranger_1.1.0       jquerylib_0.1.4        vctrs_0.4.0           \n [46] Biostrings_2.62.0      rhdf5filters_1.6.0     multtest_2.50.0       \n [49] nlme_3.1-157           iterators_1.0.14       xfun_0.30             \n [52] rvest_1.0.2            lifecycle_1.0.1        rstatix_0.7.0         \n [55] zlibbioc_1.40.0        MASS_7.3-56            scales_1.1.1          \n [58] vroom_1.5.7            hms_1.1.1              parallel_4.1.3        \n [61] biomformat_1.22.0      rhdf5_2.38.1           RColorBrewer_1.1-2    \n [64] curl_4.3.2             yaml_2.3.5             gridExtra_2.3         \n [67] memoise_2.0.1          sass_0.4.1             stringi_1.7.6         \n [70] highr_0.9              S4Vectors_0.32.3       foreach_1.5.2         \n [73] permute_0.9-7          BiocGenerics_0.40.0    GenomeInfoDb_1.30.1   \n [76] rlang_1.0.2            pkgconfig_2.0.3        bitops_1.0-7          \n [79] evaluate_0.15          lattice_0.20-45        Rhdf5lib_1.16.0       \n [82] labeling_0.4.2         htmlwidgets_1.5.4      bit_4.0.4             \n [85] tidyselect_1.1.2       plyr_1.8.7             magrittr_2.0.3        \n [88] R6_2.5.1               IRanges_2.28.0         generics_0.1.2        \n [91] DBI_1.1.2              pillar_1.7.0           haven_2.4.3           \n [94] withr_2.5.0            mgcv_1.8-39            survival_3.3-1        \n [97] abind_1.4-5            RCurl_1.98-1.6         modelr_0.1.8          \n[100] crayon_1.5.1           car_3.0-12             utf8_1.2.2            \n[103] tzdb_0.3.0             viridis_0.6.2          grid_4.1.3            \n[106] readxl_1.4.0           data.table_1.14.2      vegan_2.5-7           \n[109] reprex_2.0.1           digest_0.6.29          stats4_4.1.3          \n[112] munsell_0.5.0          viridisLite_0.4.0      bslib_0.3.1           "},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
